{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä ML Cutoff Optimizer - Basic Usage\n",
    "\n",
    "This notebook demonstrates the basic usage of **ML Cutoff Optimizer**, a library for finding optimal probability thresholds in binary classification.\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "\n",
    "1. How to create synthetic binary classification data\n",
    "2. How to train a simple model\n",
    "3. How to visualize probability distributions\n",
    "4. How to find optimal cutoff points for three decision zones\n",
    "5. How to interpret the results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Import Libraries\n",
    "\n",
    "First, let's import all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn for dataset and model\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Add project to path (if running from examples/notebooks/)\n",
    "sys.path.insert(0, '../../src')\n",
    "\n",
    "# Our library!\n",
    "from ml_cutoff_optimizer import ThresholdVisualizer, CutoffOptimizer, MetricsCalculator\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"   NumPy version: {np.__version__}\")\n",
    "print(f\"   Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 2: Create Synthetic Dataset\n",
    "\n",
    "We'll create a synthetic binary classification dataset with:\n",
    "- 1000 samples\n",
    "- 20 features\n",
    "- 2 classes (0 and 1)\n",
    "- Imbalanced classes (60% class 0, 40% class 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    weights=[0.6, 0.4],  # 60% class 0, 40% class 1\n",
    "    flip_y=0.05,  # 5% label noise\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"üìä Dataset Created:\")\n",
    "print(f\"   Training set: {len(X_train)} samples\")\n",
    "print(f\"   Test set:     {len(X_test)} samples\")\n",
    "print(f\"\\n   Class distribution (test set):\")\n",
    "print(f\"   Class 0: {np.sum(y_test == 0)} samples ({np.sum(y_test == 0)/len(y_test)*100:.1f}%)\")\n",
    "print(f\"   Class 1: {np.sum(y_test == 1)} samples ({np.sum(y_test == 1)/len(y_test)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Step 3: Train a Binary Classification Model\n",
    "\n",
    "We'll use Logistic Regression, but **any binary classifier works** (Random Forest, XGBoost, Neural Networks, etc.).\n",
    "\n",
    "The only requirement is that your model can output **probabilities** (via `predict_proba()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions and probabilities\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probability for class 1\n",
    "\n",
    "# Evaluate model (standard threshold = 0.5)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "\n",
    "print(\"ü§ñ Model Training Complete:\")\n",
    "print(f\"   Model: Logistic Regression\")\n",
    "print(f\"   Accuracy (threshold=0.5): {accuracy:.2%}\")\n",
    "print(f\"\\n   Probability statistics:\")\n",
    "print(f\"   Min:  {y_proba.min():.4f}\")\n",
    "print(f\"   Mean: {y_proba.mean():.4f}\")\n",
    "print(f\"   Max:  {y_proba.max():.4f}\")\n",
    "print(f\"\\n   Classification Report (threshold=0.5):\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Step 4: Visualize Probability Distributions\n",
    "\n",
    "Now let's visualize how the predicted probabilities are distributed.\n",
    "\n",
    "**What to look for:**\n",
    "- üîµ **Blue bars**: Overall population distribution\n",
    "- üî¥ **Red bars**: Distribution of positive class (y=1) only\n",
    "- **Good model**: Red bars concentrated on the right (high probabilities for class 1)\n",
    "- **Bad model**: Red bars spread evenly (model is guessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizer with 5% bins\n",
    "visualizer = ThresholdVisualizer(y_test, y_proba, step=0.05)\n",
    "\n",
    "# Plot distributions\n",
    "fig, ax = visualizer.plot_distributions(\n",
    "    figsize=(16, 7),\n",
    "    title=\"Probability Distribution Analysis - Basic Example\"\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà Interpretation:\")\n",
    "print(\"   - If red bars are on the RIGHT: Model gives high probabilities to positive class ‚úÖ\")\n",
    "print(\"   - If red bars are SPREAD OUT: Model is uncertain about positive class ‚ö†Ô∏è\")\n",
    "print(\"   - If red bars are on the LEFT: Model is confused (needs improvement) ‚ùå\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 5: Find Optimal Cutoffs (Three-Zone Strategy)\n",
    "\n",
    "Instead of using a single threshold (0.5), let's find **three zones**:\n",
    "\n",
    "1. **Negative Zone** (0% - X%): High confidence predictions for class 0 ‚Üí **Auto-reject**\n",
    "2. **Manual Zone** (X% - Y%): Uncertain predictions ‚Üí **Human review**\n",
    "3. **Positive Zone** (Y% - 100%): High confidence predictions for class 1 ‚Üí **Auto-accept**\n",
    "\n",
    "This reduces errors by flagging uncertain cases for manual review!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer = CutoffOptimizer(y_test, y_proba)\n",
    "\n",
    "# Suggest three zones\n",
    "cutoffs = optimizer.suggest_three_zones(\n",
    "    negative_zone_metric='specificity',  # Optimize for identifying negatives\n",
    "    positive_zone_metric='recall',       # Optimize for identifying positives\n",
    "    min_metric_value=0.80,               # Require 80% minimum performance\n",
    "    max_manual_zone_width=0.40           # Max 40% of data in manual zone\n",
    ")\n",
    "\n",
    "print(\"üéØ SUGGESTED CUTOFFS:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"   Negative Zone: 0% - {cutoffs['negative_cutoff']*100:.1f}%\")\n",
    "print(f\"   Manual Zone:   {cutoffs['negative_cutoff']*100:.1f}% - {cutoffs['positive_cutoff']*100:.1f}%\")\n",
    "print(f\"   Positive Zone: {cutoffs['positive_cutoff']*100:.1f}% - 100%\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 6: Analyze Population Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract population statistics\n",
    "pop = cutoffs['population']\n",
    "\n",
    "print(\"\\nüë• POPULATION DISTRIBUTION:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"   Negative Zone: {pop['negative_zone_count']:3d} samples ({pop['negative_zone_pct']:.1f}%)\")\n",
    "print(f\"   Manual Zone:   {pop['manual_zone_count']:3d} samples ({pop['manual_zone_pct']:.1f}%)\")\n",
    "print(f\"   Positive Zone: {pop['positive_zone_count']:3d} samples ({pop['positive_zone_pct']:.1f}%)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create pie chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "labels = ['Negative Zone\\n(Auto-Reject)', 'Manual Zone\\n(Human Review)', 'Positive Zone\\n(Auto-Accept)']\n",
    "sizes = [pop['negative_zone_pct'], pop['manual_zone_pct'], pop['positive_zone_pct']]\n",
    "colors = ['#4CAF50', '#FFC107', '#2196F3']\n",
    "explode = (0.05, 0.1, 0.05)\n",
    "\n",
    "ax.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "       shadow=True, startangle=90, textprops={'fontsize': 12, 'weight': 'bold'})\n",
    "ax.set_title('Population Distribution Across Three Zones', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "print(f\"   ‚Üí {pop['negative_zone_pct'] + pop['positive_zone_pct']:.1f}% of decisions can be AUTOMATED\")\n",
    "print(f\"   ‚Üí {pop['manual_zone_pct']:.1f}% require HUMAN REVIEW\")\n",
    "print(f\"   ‚Üí This reduces manual workload by {pop['negative_zone_pct'] + pop['positive_zone_pct']:.1f}%!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 7: Analyze Zone Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics\n",
    "neg_metrics = cutoffs['metrics']['negative_zone']\n",
    "pos_metrics = cutoffs['metrics']['positive_zone']\n",
    "\n",
    "print(\"\\nüìà ZONE PERFORMANCE METRICS:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüü¢ NEGATIVE ZONE (Auto-Reject):\")\n",
    "print(f\"   Specificity:        {neg_metrics['specificity']:.2%}  ‚Üê How well we identify true negatives\")\n",
    "print(f\"   False Positive Rate: {neg_metrics['fpr']:.2%}  ‚Üê Error rate (wrongly reject)\")\n",
    "print(f\"   Confusion Matrix: TN={neg_metrics['tn']}, FP={neg_metrics['fp']}, FN={neg_metrics['fn']}, TP={neg_metrics['tp']}\")\n",
    "\n",
    "print(\"\\nüîµ POSITIVE ZONE (Auto-Accept):\")\n",
    "print(f\"   Recall:             {pos_metrics['recall']:.2%}  ‚Üê How well we identify true positives\")\n",
    "print(f\"   Precision:          {pos_metrics['precision']:.2%}  ‚Üê Accuracy of positive predictions\")\n",
    "print(f\"   False Negative Rate: {pos_metrics['fnr']:.2%}  ‚Üê Error rate (wrongly accept)\")\n",
    "print(f\"   Confusion Matrix: TN={pos_metrics['tn']}, FP={pos_metrics['fp']}, FN={pos_metrics['fn']}, TP={pos_metrics['tp']}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Step 8: Visualize with Cutoff Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new visualization with cutoff lines\n",
    "visualizer = ThresholdVisualizer(y_test, y_proba, step=0.05)\n",
    "fig, ax = visualizer.plot_distributions(\n",
    "    figsize=(16, 7),\n",
    "    title=\"Probability Distribution with Suggested Cutoffs\"\n",
    ")\n",
    "\n",
    "# Add cutoff lines\n",
    "visualizer.add_cutoff_lines(\n",
    "    cutoffs={\n",
    "        'negative_cutoff': cutoffs['negative_cutoff'],\n",
    "        'positive_cutoff': cutoffs['positive_cutoff']\n",
    "    },\n",
    "    labels={\n",
    "        'negative_cutoff': f\"Negative Cutoff ({cutoffs['negative_cutoff']*100:.1f}%)\",\n",
    "        'positive_cutoff': f\"Positive Cutoff ({cutoffs['positive_cutoff']*100:.1f}%)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüé® Visual Interpretation:\")\n",
    "print(\"   üü¢ Green line (left):   Negative cutoff - everything LEFT is auto-rejected\")\n",
    "print(\"   üü† Orange line (right):  Positive cutoff - everything RIGHT is auto-accepted\")\n",
    "print(\"   üü° Area between lines:   Manual zone - requires human review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 9: View Full Justification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the full justification\n",
    "print(cutoffs['justification'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 10: Compare with Standard Threshold (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics at standard threshold\n",
    "standard_metrics = MetricsCalculator.calculate_all_metrics(y_test, y_proba, threshold=0.5)\n",
    "\n",
    "print(\"\\n‚öñÔ∏è COMPARISON: Three-Zone Strategy vs Standard Threshold\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nSTANDARD APPROACH (Single threshold = 0.5):\")\n",
    "print(f\"   Accuracy:  {standard_metrics['accuracy']:.2%}\")\n",
    "print(f\"   Precision: {standard_metrics['precision']:.2%}\")\n",
    "print(f\"   Recall:    {standard_metrics['recall']:.2%}\")\n",
    "print(f\"   F1-Score:  {standard_metrics['f1']:.2%}\")\n",
    "print(f\"   ‚Üí 100% of decisions are automated (no human review)\")\n",
    "print(f\"   ‚Üí Error rate: {(1 - standard_metrics['accuracy'])*100:.1f}%\")\n",
    "\n",
    "print(\"\\nTHREE-ZONE STRATEGY:\")\n",
    "print(f\"   Negative Zone Specificity: {neg_metrics['specificity']:.2%}\")\n",
    "print(f\"   Positive Zone Recall:      {pos_metrics['recall']:.2%}\")\n",
    "print(f\"   ‚Üí {pop['negative_zone_pct'] + pop['positive_zone_pct']:.1f}% automated with HIGH CONFIDENCE\")\n",
    "print(f\"   ‚Üí {pop['manual_zone_pct']:.1f}% flagged for human review (uncertain cases)\")\n",
    "print(f\"   ‚Üí Lower error rate on automated decisions\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n‚úÖ ADVANTAGES OF THREE-ZONE STRATEGY:\")\n",
    "print(\"   1. Higher confidence on automated decisions\")\n",
    "print(\"   2. Reduces critical errors by flagging uncertain cases\")\n",
    "print(\"   3. Allows human expertise where it matters most\")\n",
    "print(\"   4. Balances automation efficiency with accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Summary & Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Standard threshold (0.5) is not always optimal** - It treats all predictions equally\n",
    "\n",
    "2. **Three-zone strategy is smarter** - It recognizes that some predictions are more confident than others\n",
    "\n",
    "3. **Manual review zone is valuable** - Instead of making wrong decisions automatically, flag uncertain cases for humans\n",
    "\n",
    "4. **Visualization is key** - Overlapping histograms show where the model is confident vs uncertain\n",
    "\n",
    "5. **Customizable metrics** - You can optimize for different goals (precision, recall, F1, etc.)\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "- **Spam Detection**: Auto-block obvious spam, auto-allow obvious ham, manually review borderline emails\n",
    "- **Credit Risk**: Auto-reject high risk, auto-approve low risk, manually review medium risk\n",
    "- **Medical Diagnosis**: Auto-negative for healthy, auto-positive for critical, manual review for uncertain\n",
    "- **Fraud Detection**: Auto-block suspicious, auto-allow normal, investigate borderline cases\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "Check out the other notebooks:\n",
    "- `02_spam_detection.ipynb` - Real-world spam classification example\n",
    "- `03_credit_risk.ipynb` - Credit approval with cost-benefit analysis\n",
    "\n",
    "---\n",
    "\n",
    "**‚≠ê If you found this useful, star the repository!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
